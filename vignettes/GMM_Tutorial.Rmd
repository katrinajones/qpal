---
title: "GMM Tutorial"
author: "Katrina Jones & David Polly"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
extdatafiles <- system.file("extdata", package="qpal")
knitr::opts_knit$set(root.dir = extdatafiles)
library(rgl)
knitr::knit_hooks$set(webgl = hook_webgl)
knitr::opts_chunk$set(fig.width=3, fig.height=3)
```


This tutorial includes code and excersizes used in the 2018 Analytical Paleobiology Course, hosted at University of Florida. Lecture slide pdfs including theoretical content are provided at XXX

Code and datasets associated with this tutorial are available at https://github.com/katrinajones/qpal

These can be installed with `devtools` using `install_github("katrinajones/qpal", build_vignette=T)`

#Day 1 - Intro to Geometric Morphometrics in R

##Part 1: Introduction to Geomorph Package

Geomorph provides a flexible tool for analyzing geometric morphometric data. For more information see `?(geomorph)`.

Loading up some data:

```{r, warning=F}
#load geomorph
library(geomorph, quietly=T)
library(qpal, quietly=T) #package including functions for the course

#Get example data - plethodon salamander heads
data("plethodon") #Load data into environment

#What's included in the dataset
summary(plethodon)

```

Converting between wide and long data formats:

```{r}
#Converting between wide and long formats
#Long to wide
wide<-two.d.array(plethodon$land)
wide[1:5,1:5]
#Wide to long
long<-arrayspecs(wide, 12, 2)
long[,,1]
```

Arrays are much more handy for handling GMM data in R because you can easily access all elements with simple code

```{r, results='hide'}
#Indexing arrays
#Get first specimen
long[,,1]
#Get first landmark of all specimens
long[1,,]
#Get X coordinates of all landmarks
long[,1,]
```

Geomorph data frames are a useful way of tidying all your data associated with your landmarks together into a single object, and are the native and sometimes required format for geomorph functions

```{r}
#Create geomorph data frame
plethgdf<-geomorph.data.frame(landmarks=long, species=plethodon$species, 
                              site=plethodon$site)
summary(plethgdf)
```

Once your data is all combined into a single geomorph data frame, its very useful to be able to subset it all at once, keeping track of all your separate variables. Iâ€™ve included a custom subsetting function I wrote for this purpose.

```{r, fig.show='hold'}
#plot first five specimens
plot(plethgdf$landmarks[,,1])

#plot raw data together
plotAllSpecimens(plethgdf$landmarks, mean=F)
```
```{r, results='hide'}
#plot in same shape space
Pcoords<-gpagen(plethgdf$landmarks)
plethgdf<-geomorph.data.frame(plethgdf, coords=Pcoords$coords, 
                              size=Pcoords$Csize)
```
```{r, fig.height=5, fig.width=5}
plotAllSpecimens(plethgdf$coords, mean=T, links=plethodon$links)

```

Comparing specimens

```{r, results='hide'}
#Are there any wierd specimens
plotOutliers(plethgdf$coords)
```
```{r, fig.show='hold'}
#Let's compare them
shape1<-mshape(plethgdf$coords)#consensus shape
shape2<-plethgdf$coords[,,14]

#Thin plate spline
plotRefToTarget(shape1, shape2, method=c("TPS"), mag=2)
#Lollipops
plotRefToTarget(shape1, shape2, method=c("vector"), mag=10)
#Points
plotRefToTarget(shape1, shape2, method=c("points"), mag=10)
```

##Part 2: Step-by-step morphometric analysis

This section provides a quick overview of the steps of a GMM analysis in R, which will be followed by a practical in which you will collect and run your own data.

The R package Stereomorph provides a nice interface for collecting landmarks and curves in 2D. You must have either Chrome or Safari installed for this to work.

```{r, results='hide'}
library(StereoMorph)
library(abind)

#Digitize 2D landmarks with Stereomorph
extdatafiles <- system.file("extdata", package="qpal")#find directory where external data are saved
setwd(extdatafiles)
```
```{r, eval=FALSE}
#Name landmarks
lands<-c("condyle", "angular", "coronoid", "posterior molar", "tip incisor")
#Name curves
curves<-matrix(c("condtocor", "condtoang","condyle","condyle","coronoid",
                 "angular"), nrow=2,ncol=3)
#Digitize specimens
digitizeImage(image.file = 'ShrewsAndMarmots', shapes.file = 'teeth',
              landmarks.ref = lands, curves.ref = curves)
```

Read in the data

```{r, results='hide'}

#Look at data based on fixed landmarks only
teeth<-readShapes('teeth')
fixed<-teeth$landmarks.scaled

#Procrustes fit
gpa.lands <- gpagen(fixed)
```
```{r, fig.show='hold'}
plotAllSpecimens(fixed)
plot(gpa.lands)
```

Now add the curve sliders

```{r}
 #With Sliding semi-landmarks
curves<-teeth$curves.scaled

#resample curves to 5 fixed landmarks
nfixed<-5
totfixed<-nfixed+2
curvelands<-list()
curvelands<-lapply(curves, function (x) lapply(x, pointsAtEvenSpacing, n=totfixed))#Resample
curvelands<-lapply(curvelands, do.call, what=rbind)#merge
curvelands<-array(unlist(curvelands), dim=c((2*totfixed),2,5))#convert to array
curvelands<-curvelands[-c(1,totfixed, (totfixed+1),(2*totfixed)),,]#remove fixed points
rownames(curvelands)<-rep(c("cu1", "cu2"), each=nfixed) #label
lands<-abind::abind(fixed, curvelands, along=1) #join with fixed
```
 
We can write to TPS format for use in other software, or read in files created elsewhere in that format

```{r, eval=FALSE}
#Read and write TPS file for use in other software
writeland.tps(lands, "shrewtest.tps")
readland.tps("shrewtest.tps", specID=("ID"))
```

Now we need to make a 'sliders' file to tell geomorph which landmarks to slide during the procrustes fit. Here I'm using custom code which makes the sliders file based on the curve labels

```{r, results='hide'}
#make sliders file
sliders<-makesliders(rownames(lands),id=c("cu1", "cu2"), begin=c(1,1),
                     end=c(3,2))

#Procrustes fit
gpa.lands <- gpagen(lands, curves=sliders)
```
```{r, fig.show='hold'}
plot(gpa.lands$consensus, col=palette()[as.factor(rownames(lands))], pch=19)
plot(gpa.lands)
plotRefToTarget(gpa.lands$coords[,,1], gpa.lands$consensus)
```

Now we'll try with a much bigger dataset, based on [insert citation]

```{r}
##Now lets try with a big dataset of shrewteeth!
#shrew teeth
data("shrewteeth")
summary(shrewteeth)
```
```{r, results='hide'}
#Procrustes fit
proc<-gpagen(shrewteeth)
```
```{r, fig.show='hold'}
#Plot raw data
plotAllSpecimens(shrewteeth)
#plot procrustes coordinates
plot(proc)
```

Now lets try putting it in a geomorph data frame

```{r, fig.height=5, fig.width=5}
#Make geomorph data frame
group<-as.factor(rep(c("a", "b"), length=dim(shrewteeth)[[3]]))#make up some labels
shrewdf<-geomorph.data.frame(raw=shrewteeth, coords=proc$coords,
                             size=proc$Csize, group=group)

#subsample by labels
a<-subsetgeom(shrewdf, "spec", which(shrewdf$group=="a"), keep=T)

#PCA
pca.lands <- plotTangentSpace(shrewdf$coords, label=TRUE,
                              groups = palette()[shrewdf$group])
shrewdf<-geomorph.data.frame(shrewdf, scores=pca.lands$pc.scores)
```

Now lets try an interactive 3D plot

```{r testgl,fig.height=6, fig.width=6, webgl=TRUE}
plot3d(shrewdf$scores[,1:3])#interactive 3D plots
text3d(shrewdf$scores[,1:3],texts=rownames(shrewdf$scores),pos=4,cex=.5)
```

Compare to the mean shape

```{r, fig.show='hold'}
#Consensus shape
consensus <- mshape(shrewdf$coords)
plotAllSpecimens(shrewdf$coords)
#centroid - midpoint of the landmarks
centroid <- apply(shrewdf$coords,2,mean)
points(centroid[1],centroid[2],col="Red", cex=2)

#Visualizing shapes
plotRefToTarget(consensus,shrewdf$coords[,,1])
```

##Practical - GMM analsysis of faces

Now try it out yourself! Take some photos of your friends faces, ideally from different angles, and try running your own morphometric analysis. Do different faces group separately? Or does error associated with photo angle swamp out the signal?

#Day 2 - GMM analysis in detail

##Procrustes superimposition

Calculating Procrustes distances by hand

```{r}
#Calculate distance
A<-shrewdf$raw[,,1]
B<-shrewdf$raw[,,2]
pdist<-sqrt(sum((A-B)^2))
pdist

#Consensus shape
consensus <- mshape(shrewdf$coords)

#Procrustes distance
dists <- array(dim=dim(shrewdf$coords)[3])
for(i in 1:dim(proc$coords)[3]) 
{ dists[i] <- sqrt(sum((shrewdf$coords[i]-consensus)^2)) }
head(sort(dists))
```

Calculate centroid size

```{r}
#Centroid size
shape <- A
centroid <- apply(shape,2,mean)
centroidsize <- sqrt(sum((t(t(shape)-centroid))^2))

plot(shape, xlim=c(-800,800), ylim=c(-800,800))
points(t(centroid), col="red", pch=19)
```

Run through the steps of a Procrustes Superimposition: Translation, scaling, rotation

Translation

```{r, fig.show='hold'}
#Translation
newshape<-t(t(shape)-centroid)

#plot
plot(shape, xlim=c(-800,800), ylim=c(-800,800), main="Translate")
points(newshape, col="blue")
points(t(centroid), col="red")
newcent<-apply(newshape, 2, mean)
points(t(newcent), pch=19,col="Red")

#centroid size doesn't change
newcentsize<-sqrt(sum((t(t(newshape)-newcent))^2))
centroid
newcentsize

#scale
resizedshape <- newshape / centroidsize

#plot
plot(c(-1,1),c(-1,1),xlab="x",ylab="y", type="n", main="Scale and Rotate")
points(t(newcent), pch=19)
points(resizedshape, pch=19,col="Red")

angle <- 45 * pi / 180
rotmat <- matrix(c(cos(angle),-sin(angle),sin(angle),cos(angle)),byrow=T,ncol=2)

#plot
points(resizedshape%*%rotmat, pch=19,col="Blue")
```

##Principal Components Analysis

Three methods for calculating total variance which should always give the same results

```{r}
nspec<-dim(shrewdf$raw)[3]
nspec
sum(apply(shrewdf$coords, 3, function (x) sum((x-consensus)^2)))/(nspec-1)
sum(pca.lands$sdev^2)
sum(pca.lands$pc.scores^2)/(nspec-1)
```

PCA Calculation

```{r}
#convert procrustes coordinates to wide format for use outside geomorph
coords2d<-two.d.array(shrewdf$coords) 
consensusvec<-apply(coords2d, 2, mean)#consensus in vector format

#calculate residuals
resids<-sweep(proc$coords, c(1,2), consensus)

#calculate covariance matrix
P<-cov(two.d.array(resids))

#single value decomposition
pca.stuff<-svd(P)
eigenvalues <- pca.stuff$d
eigenvectors <- pca.stuff$u
scores <- two.d.array(resids)%*%eigenvectors
```

Calculate variances again to check

```{r}
sum(apply(coords2d,2,var)) # total variance of Procrustes coordinates
sum(apply(two.d.array(resids),2,var)) # total variance of Procrustes residuals
sum(pca.stuff$d) # total variance of singular values
sum(apply(scores, 2, var)) # total variance of scores
```

Compare plots

```{r, fig.show='hold'}
pca<-plotTangentSpace(shrewdf$coords, warpgrids=F)
plot(scores[,1:2])
```

##Statistical analysis of GMM data

###Regression analysis

We will use the plethodon example dataset from above to try out some data analysis in geomorph, using the geomorph dataframe 'plethgdf'.

```{r, results='hide'}
##example with plethodon dataset
pc.scores<-plotTangentSpace(plethgdf$coords, warpgrids=F)
plethgdf<-geomorph.data.frame(plethgdf, pcscores=pc.scores$pc.scores)
```

We can run the analysis univariately using PC1, however this is not a good idea because it ignores much of the variation. Here we show an example, just to illustrate univariate regression in r 

```{r, fig.show='hold'}
#Univariate regression against PC1
#Not including all the variation - shouldn't do this!
plot(log(plethgdf$size),plethgdf$pcscores[,1])
w <- lm(plethgdf$pcscores[,1]~ log(plethgdf$size))
w # gives only coefficients & formula
summary(w) # gives much more info: stats, P, etc.
abline(w) # adds regression line to plot
```

However, it is much better to run the analysis multivariately, taking into account all variation. Geomorph has many tools for the multivariate analysis of shape, which run directly on the Procrustes Coordinates. Further, statistical tests within the package are designed to accomodate high dimensional data. For more information see `?ProcD.lm`

```{r}
#Multivariate in geomorph - correct way!
pleth.lm<-procD.lm(coords~log(size), data=plethgdf, print.progress = F)
pleth.lm
```

If you are interested in the relationship between size and shape, there is also a built in function for allometric analysis. Though testing is essential the same as `ProcD.lm`, it includes additional tools for visualizing size-related shape.

```{r, fig.show='hold', fig.height=5, fig.width=5}
#Special function for examining allometry specifically
pleth.allom<-procD.allometry(coords~size,logsz=T,data=plethgdf, print.progress = F)
pleth.allom

#Now also outputs allometric components with shape warps
#Shape scores from regression of shape on size
plot(pleth.allom, method="RegScore")

#Predicted shapes based on size
#PC1 of predicted values
plot(pleth.allom, method="PredLine")
```

Further, it is possible to 'size-correct' your shape data, by removing the shape most associated with size. Remember, absolute size has already been removed during the Procrustes fit. Thus, this allometric component of shape reflects the remaining shape which is correlated with size. You need to think about if you want to remove this or not!

```{r}
#Can get size-corrected residuals
plethAnova <- procD.lm(pleth.allom$formula,
                       data = pleth.allom$data, print.progress = F)
shape.resid <- arrayspecs(plethAnova$residuals,
                          p=dim(plethgdf$coords)[1], k=dim(plethgdf$coords)[2]) # allometry-adjusted residuals
adj.shape <- shape.resid + array(mshape(plethgdf$coords), dim(shape.resid)) # 
```

We can also take into account different groups when considering allometry

```{r, fig.height=5, fig.width=5}
##Add groups - MANCOVA
pleth.allom<-procD.allometry(coords~size,f2=~species,logsz=T,data=plethgdf, print.progress = F)

plot(pleth.allom, method="PredLine")
```

We can also visualize shape variation associated with size

```{r}
#Compare min and max size associated shapes
plotRefToTarget(pleth.allom$Ahat.at.min, pleth.allom$Ahat.at.max, mag=5)
```

###MANOVA

We can also use `ProcD.lm` to examine the relationship of shape with categorical variables

```{r, fig.show='hold', warning=F}
#ANOVA
pleth.anova<-procD.lm(coords~species, data=plethgdf, print.progress = F)
pleth.anova$aov.table
pleth.anova<-procD.lm(coords~species+site, data=plethgdf,print.progress = F)
pleth.anova$aov.table
pleth.anova<-procD.lm(coords~species*site, data=plethgdf, print.progress = F)
pleth.anova$aov.table

# diagnostic plots, including plotOutliers
plot(pleth.anova, type = "diagnostics", outliers = TRUE)
# PC plot rotated to major axis of fitted values
plot(pleth.anova, type = "PC", pch = 19, col = "blue")
```

To run posthoc tests between groups, or explicitly test the fit of two nested models, `advanced.ProcD.lm` can be used.

```{r}
#Post-hoc comparisons
pleth.posthoc<-advanced.procD.lm(coords~species,f2=~1, groups=~species,
                                 data=plethgdf, print.progress = F)
pleth.posthoc

#group and covariate
pleth.posthoc<-advanced.procD.lm(coords~species*log(size),f2=~1, groups=~species*site, slopes= ~log(size), data=plethgdf, print.progress = F)
pleth.posthoc$anova.table

#Compare with or without interaction term
pleth.posthoc<-advanced.procD.lm(coords~species*site,f2=~species+site, groups=~species*site, data=plethgdf, print.progress = F)
pleth.posthoc$anova.table
```

##Practical - Analysis of Carnivoran Tarsals (2D)

Now try for yourself, using an example dataset of photos of Carnivoran tarsals, in the folder `2Dtarsals`. Locate this directory using `system.file("extdata", package="qpal")`. Associated data are located in `Tarsalsdata.csv`. To analyze example landmarks, there is a ready-made geomorph dataframe which can be accessed using `data("tarsalsdf")`.

##Visualizing 3D data in R

Geomorph offers great tools for visualizing shape change in 3D. Using a surface ply file (located in `/Tarsals/plys`), we can warp the surface shape to our procrustes consensus shape. From there, we can use this surface to visualize shape variation

First choose a specimen to be the base of your warps. This specimen should have fairly generic morphology and lie near the middle of the morphospace.

```{r}
#3D surface warps
#Choose specimen
specfit<-c("Lynx_rufus")
```

Next we will warp this base specimen to the mean shape for the dataset

```{r warprgl,fig.height=4, fig.width=4, webgl=TRUE, results='hide'}
#calculate warps
mean<-mshape(tarsalsdf$coords3d)

#read surface ply file
surf<-read.ply(paste0("Tarsals/plys/", specfit, ".ply"))

#warp
wmesh<-warpRefMesh(surf,tarsalsdf$land3d[,,which(dimnames(tarsalsdf$coords3d)[[3]]==specfit)], ref=mean)
```

Now we can use the wmesh object anywhere `geomorph` calls for a mesh. This will allow us to visualize shape variation as surface warps

```{r warp2rgl,fig.height=5, fig.width=5, webgl=TRUE, results='hide'}
#visualize shape
plotTangentSpace(tarsalsdf$coords3d, mesh=wmesh, label = tarsalsdf$common, groups = tarsalsdf$family)

```

##Analysis of 3D Tarsals

How can our estimates of shape change if we use 3D instead of 2D data? Now repeat your non-phylogenetic and phylogenetic analyses on a 3D dataset contained within the `tarsalsdf` dataframe. Access it using `tarsalsdf$lands3d`.

#Day 3 - GMM on Trees

First we will upload a phylogenetic tree to match our tarsals dataset. This is a time callibrated phylogeny generated by `timetree.org`.

```{r, fig.height=5, fig.width=5}
#Use 2D tarsal data from yesterday
data("tarsalsdf")

#Read tree - created from timetree.org
require(phytools)
tree<-read.newick("tarsaltree.nwk")
tree$tip.label<-gsub("_", " ", tree$tip.label)#make names match
par(mar=c(1,1,1,1))
plot(tree)
```

##Simulating GMM data on a tree

We will use the package `mvMORPH` to simulate evolution of multivariate traits on a tree. Since morphometric traits (Procrustes coordinates) strongly covary, we expect the rate of evolution of each coordinate to be related. `mvMorph` allows us to use a rate matrix, which can take into account covariation between traits in their evolutionary patterns.

First, let's assume random rates accross all traits, and theta equivalent to the mean shape.

```{r, results='hide', warning=F}
##Simulating morphological evolution on a tree
require(mvMORPH, quietly=T)
ntraits<-34#2*no of landmarks
simdat<-two.d.array(tarsalsdf$coords)[,1:ntraits]


#simulate without prior rate info
sigmamat<-matrix(rnorm(ntraits*ntraits),ntraits)#random rates
theta<-colMeans(simdat)#mean values
sim.null<-mvMORPH::mvSIM(tree, nsim=4, model=c("BM1"),
                     param=list(ntraits=ntraits, sigma=sigmamat, theta=theta))
```
```{r, fig.height=5, fig.width=5}
#Look at data
par(mfrow=c(2,2))
par(mar=c(2,2,2,2))
for(i in 1:4){
plotTangentSpace(arrayspecs(sim.null[[i]], (ntraits/2), 2),
                 label = tarsalsdf$common, groups = tarsalsdf$family, warpgrids=F)
}
```

Now lets specify more realistic parameters for the rate matrix, by calculating it from the real data. To do this we need to reduce the number of landmarks, since the sample is so small.

```{r, results='hide'}
#Base simulation on real rates/covariance between vars
# must have fewer vars than species
ntraits<-12
simdat<-two.d.array(tarsalsdf$coords)[,1:ntraits]
bm<-mvBM(tree, data=simdat,model=c("BM1"))#calculate rate covariance
sim<-simulate(bm,tree=tree, 4)
```
```{r, fig.height=5, fig.width=5}

#Look at data
par(mfrow=c(2,2))
par(mar=c(2,2,2,2))
for(i in 1:4){
  plotTangentSpace(arrayspecs(sim[[i]], (ntraits/2), 2),
      label = tarsalsdf$common, groups =tarsalsdf$family,warpgrids=F)
}

```

##Visualizing evolution on trees

```{r, fig.height=5, fig.width=5}

#Plot a phylomorphospace
phy.tar<-plotGMPhyloMorphoSpace(tree, tarsalsdf$coords, tip.labels = F, ancStates = T, plot.param = list(t.bg=palette()[tarsalsdf$family]))

```

Geomorph will also calculate the ancestral state shapes at the nodes

```{r, fig.show='hold'}
#Now we can also visualize ancestral states
anc.st<-arrayspecs(phy.tar, nrow(tarsalsdf$coords), 2)
plot(anc.st[,,1])
#Evolution along branch
plotRefToTarget(anc.st[,,1],anc.st[,,2], mag=3)
```

You can also use `phytools` to make a 3D phylomorphospace

```{r results='hide'}
a<-plotTangentSpace(tarsalsdf$coords,warpgrids = F,axis1=1,axis2=2, verbose=F)
```
```{r phyrgl,fig.height=5, fig.width=5, webgl=TRUE}
open3d()
plotdat<-a$pc.scores[,1:3]
colnames(plotdat)<-c("","","")#prevent axis labels
obj<-phytools::phylomorphospace3d(tree,plotdat, method="dynamic",
                                  control=list(ftype="off",spin=F, box=F), cex.symbol=0.5)

##Color by groups
spheres3d(a$pc.scores[,1:3], color=palette()[tarsalsdf$family], r=0.01)
bbox3d(color = c("white"),shininess=15, alpha=0.3,xat=c(10), xlab="",yat=c(10), ylab="",zat=c(10), zlab="")
text3d((a$pc.scores[,1:3]+0.02), texts = substr(tarsalsdf$species,1,3))
```

##Phylogenetic analyses

```{r, fig.show='hold'}
#Test for phylogenetic signal
physignal(tarsalsdf$coords, tree, print.progress = F)

##Phylogenetic generalized least squares
#stance
pgls.tar<-procD.pgls(coords~stance, phy=tree, data=tarsalsdf, print.progress = F)
pgls.tar$aov.table

#size and stance with interaction
pgls.tar<-procD.pgls(coords~log(mass)*stance, phy=tree, data=tarsalsdf,print.progress = F)
pgls.tar$aov.table

#Compare rates of evolution between families
names(tarsalsdf$family)<-tarsalsdf$species
rate.comp<-compare.evol.rates(tarsalsdf$coords, tree, gp=tarsalsdf$family, print.progress = F)

plot(rate.comp)
rate.comp$sigma.d.gp
rate.comp$pairwise.pvalue
```


##Practical

Now try applying some phylogenetic analyses to the 3D tarsals dataset. How do the 2D and 3D results differ?



